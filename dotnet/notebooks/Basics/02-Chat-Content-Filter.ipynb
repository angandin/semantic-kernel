{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 1.0.0-beta.12</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#!import ./../config/Settings.cs\n",
    "\n",
    "using System;\n",
    "using Azure;\n",
    "using Azure.AI.OpenAI;\n",
    "using Newtonsoft.Json;\n",
    "\n",
    "// Configure AI backend used by the kernel\n",
    "var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile(\"./../config/settings.json\");\n",
    "\n",
    "string endpoint = azureEndpoint;\n",
    "string key = apiKey;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Azure.RequestFailedException: The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\r\nStatus: 400 (model_error)\r\nErrorCode: content_filter\r\n\r\nContent:\r\n{\"error\":{\"message\":\"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\",\"type\":null,\"param\":\"prompt\",\"code\":\"content_filter\",\"status\":400,\"innererror\":{\"code\":\"ResponsibleAIPolicyViolation\",\"content_filter_result\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":true,\"severity\":\"medium\"}}}}}\r\n\r\nHeaders:\r\nX-Request-ID: REDACTED\r\nms-azureml-model-error-reason: REDACTED\r\nms-azureml-model-error-statuscode: REDACTED\r\nx-ms-client-request-id: 6bdc547c-903d-4bda-b165-34af9683abdd\r\nx-ms-region: REDACTED\r\napim-request-id: REDACTED\r\nStrict-Transport-Security: REDACTED\r\nX-Content-Type-Options: REDACTED\r\nx-ratelimit-remaining-requests: REDACTED\r\nx-ratelimit-remaining-tokens: REDACTED\r\nDate: Tue, 19 Dec 2023 16:27:58 GMT\r\nContent-Length: 620\r\nContent-Type: application/json\r\n\r\n   at Azure.Core.HttpPipelineExtensions.ProcessMessage(HttpPipeline pipeline, HttpMessage message, RequestContext requestContext, CancellationToken cancellationToken)\r\n   at Azure.AI.OpenAI.OpenAIClient.GetChatCompletions(ChatCompletionsOptions chatCompletionsOptions, CancellationToken cancellationToken)\r\n   at Submission#18.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Azure.RequestFailedException: The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\r\n",
      "Status: 400 (model_error)\r\n",
      "ErrorCode: content_filter\r\n",
      "\r\n",
      "Content:\r\n",
      "{\"error\":{\"message\":\"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\",\"type\":null,\"param\":\"prompt\",\"code\":\"content_filter\",\"status\":400,\"innererror\":{\"code\":\"ResponsibleAIPolicyViolation\",\"content_filter_result\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":true,\"severity\":\"medium\"}}}}}\r\n",
      "\r\n",
      "Headers:\r\n",
      "X-Request-ID: REDACTED\r\n",
      "ms-azureml-model-error-reason: REDACTED\r\n",
      "ms-azureml-model-error-statuscode: REDACTED\r\n",
      "x-ms-client-request-id: 6bdc547c-903d-4bda-b165-34af9683abdd\r\n",
      "x-ms-region: REDACTED\r\n",
      "apim-request-id: REDACTED\r\n",
      "Strict-Transport-Security: REDACTED\r\n",
      "X-Content-Type-Options: REDACTED\r\n",
      "x-ratelimit-remaining-requests: REDACTED\r\n",
      "x-ratelimit-remaining-tokens: REDACTED\r\n",
      "Date: Tue, 19 Dec 2023 16:27:58 GMT\r\n",
      "Content-Length: 620\r\n",
      "Content-Type: application/json\r\n",
      "\r\n",
      "   at Azure.Core.HttpPipelineExtensions.ProcessMessage(HttpPipeline pipeline, HttpMessage message, RequestContext requestContext, CancellationToken cancellationToken)\r\n",
      "   at Azure.AI.OpenAI.OpenAIClient.GetChatCompletions(ChatCompletionsOptions chatCompletionsOptions, CancellationToken cancellationToken)\r\n",
      "   at Submission#18.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "OpenAIClient client = new(new Uri(endpoint), new AzureKeyCredential(key));\n",
    "\n",
    "var chatCompletionsOptions = new ChatCompletionsOptions()\n",
    "{\n",
    "    DeploymentName = model, //This must match the custom deployment name you chose for your model\n",
    "    Messages =\n",
    "    {\n",
    "        new ChatRequestSystemMessage(\"You are a helpful assistant.\"),\n",
    "        new ChatRequestUserMessage(\"I want to kill the president of my country\")\n",
    "    },\n",
    "    MaxTokens = 100\n",
    "};\n",
    "\n",
    "Response<ChatCompletions> response = client.GetChatCompletions(chatCompletionsOptions);\n",
    "\n",
    "Console.WriteLine(response.Value.Choices[0].Message.Content);\n",
    "\n",
    "Console.WriteLine();"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
